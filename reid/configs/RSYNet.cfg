[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

# Downsample1

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 1x        3
[resshuffleblock]
filters=64


[resshuffleblock]
filters=128

[resshuffleblock]
filters=64

[resshuffleblock]
filters=64

# Downsample2     5

[shuffleblock]
stride = 2
filters=128

# 2x 1
[resshuffleblock]
filters=256


[resshuffleblock]
filters=128

[resshuffleblock]
filters=128


# Downsample 3   10
[shuffleblock]
stride = 2
filters=256

# 1 8x1
[resshuffleblock]
filters=512


# 1 8x 2
[shuffleblock]
filters=256


# 1 8x 3        13
[shuffleblock]
filters=256



# Downsample4
[shuffleblock]
stride = 2
filters=512


# 2 8x 1
[shuffleblock]
filters=1024

# 2 8x 2     19
[shuffleblock]
filters=1024

# 2 8x 3
[shuffleblock]
filters=1024



# Downsample 5     24
# 4x   0
[shuffleblock]
stride = 2
filters=2048

#4x   1
[shuffleblock]
filters=2048

[convolutional]
batch_normalize=1
filters=2048
size=1
stride=1
pad=1
activation=leaky







